{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flying-classification",
   "metadata": {},
   "source": [
    "###  Connect to Your Workspace\n",
    "#### The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "- In the azure portal create a workspace\n",
    "- After creating the workspace open ML studio with the workspace and create a compute instance\n",
    "- In the compute instance open the jupyter notebook\n",
    "- open new python file\n",
    "- connect to the workspace you created using the below code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "employed-blackberry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22.0 workspace19\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "ws=Workspace.from_config()\n",
    "print(azureml.core.VERSION,ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-cancer",
   "metadata": {},
   "source": [
    "### Create an Azure ML experiment in your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lined-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-experiment\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model,Experiment\n",
    "exp=Experiment(workspace=ws,name='iris-experiment')\n",
    "print(exp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-zambia",
   "metadata": {},
   "source": [
    "### Train and Register a Model\n",
    "#### import required libraries for training and registering the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cardiovascular-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-worthy",
   "metadata": {},
   "source": [
    "#### Start an interactive session using the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accompanied-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "run=exp.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-continuity",
   "metadata": {},
   "source": [
    "#### load the data from the specific folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "still-singing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data.......................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('loading data.......................')\n",
    "data=pd.read_csv('data/IRIS.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-spouse",
   "metadata": {},
   "source": [
    "#### convert the target labels from string to int using label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fuzzy-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "# Encode labels in column 'species'. \n",
    "data['species']= label_encoder.fit_transform(data['species']) \n",
    "\n",
    "data['species'].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-league",
   "metadata": {},
   "source": [
    "#### # Split data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "asian-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=data[['sepal_length','sepal_width','petal_length','petal_width']].values,data['species'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-distance",
   "metadata": {},
   "source": [
    "#### Train a decision tree model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "organic-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a decision tree model\n",
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-request",
   "metadata": {},
   "source": [
    "#### Evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "primary-click",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9852941176470588\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test,y_scores,multi_class=\"ovr\",average=\"weighted\")\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-completion",
   "metadata": {},
   "source": [
    "#### Save the trained model as a pkl file a specific directory and complete the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_file = 'iris_model2.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-lunch",
   "metadata": {},
   "source": [
    "#### Register the model in azure ml studio for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continental-education",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run.register_model(model_path='outputs/iris_model2.pkl', model_name='iris_model2',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-eligibility",
   "metadata": {},
   "source": [
    "### Deploy a Model as a Web Service\n",
    "\n",
    "Deploying an Azure Machine Learning model as a web service creates a REST API endpoint. You can send data to this endpoint and receive the prediction returned by the model.\n",
    "\n",
    "You create a web service when you deploy a model to your local environment, Azure Container Instances, Azure Kubernetes Service, or field-programmable gate arrays (FPGA). You retrieve the URI used to access the web service by using the Azure Machine Learning SDK. If authentication is enabled, you can also use the SDK to get the authentication keys or tokens.\n",
    "\n",
    "When you deploy a model, a Webservice object is returned with information about the service.\n",
    "\n",
    "First, let's determine what models you have registered in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "wanted-master",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_model2 version: 1\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.9852941176470588\n",
      "\t Accuracy : 0.9777777777777777\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-kinase",
   "metadata": {},
   "source": [
    "#### Right, now let's get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "external-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_model2 version 1\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['iris_model2']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-living",
   "metadata": {},
   "source": [
    "#### We're going to create a web service to host this model, and this will require some code and configuration files; so let's create a folder for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bibliographic-chicken",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_service2 folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'iris_service2'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = os.path.join(experiment_folder,\"score_iris.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-benefit",
   "metadata": {},
   "source": [
    "The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in an entry script (often called a scoring script) that will be deployed to the web service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hidden-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./iris_service2/score_iris.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('iris_model2')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['Iris-sectosa', 'Iris-versicolor','Iris-verginica']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-static",
   "metadata": {},
   "source": [
    "The web service will be hosted in a container, and the container will need to install any required Python dependencies when it gets initialized. In this case, our scoring code requires scikit-learn, so we'll create a .yml file that tells the container host to install this into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prospective-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in ./iris_service2/iris_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package('scikit-learn')\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = os.path.join(experiment_folder,\"iris_env.yml\")\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-spelling",
   "metadata": {},
   "source": [
    "Now you're ready to deploy. We'll deploy the container a service named diabetes-service. The deployment process includes the following steps:\n",
    "\n",
    "- Define an inference configuration, which includes the scoring and environment files required to load and use the model.\n",
    "- Define a deployment configuration that defines the execution environment in which the service will be hosted. In this case, an Azure Container Instance.\n",
    "- Deploy the model as a web service.\n",
    "- Verify the status of the deployed service.\n",
    "\n",
    "Deployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of Healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "israeli-confidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running........................................................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   entry_script=script_file,\n",
    "                                   conda_file=env_file)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"iris-service2\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-exemption",
   "metadata": {},
   "source": [
    "Hopefully, the deployment has been successful and you can see a status of Healthy. If not, you can use the following code to check the status and get the service logs to help you troubleshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cardiovascular-natural",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "print(service.state)\n",
    "#print(service.get_logs())\n",
    "\n",
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-tulsa",
   "metadata": {},
   "source": [
    "\n",
    "Take a look at your workspace in Azure ML Studio and view the Endpoints page, which shows the deployed services in your workspace.\n",
    "\n",
    "You can also retrieve the names of web services in your workspace by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "civilian-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-service2\n"
     ]
    }
   ],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-adapter",
   "metadata": {},
   "source": [
    "Use the Web Service\n",
    "With the service deployed, now you can consume it from a client application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "historic-assessment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower : [6.7, 3.9, 5.2, 5.3]\n",
      "{\"data\": [[6.7, 3.9, 5.2, 5.3]]}\n",
      "[\"Iris-verginica\"]\n",
      "Iris-verginica\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[6.7,3.9,5.2,5.3]]\n",
    "print ('flower : {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "print(input_json)\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "print(predictions)\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "absolute-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [3.7, 1.0, 5.2, 2.3] Iris-verginica\n",
      "Patient [1.1, 3.5, 0.4, 0.2] Iris-sectosa\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# This time our input is an array of two feature arrays\n",
    "x_new = [[3.7,1.0,5.2,2.3],\n",
    "        [1.1,3.5,0.4,0.2]]\n",
    "\n",
    "# Convert the array or arrays to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes.\n",
    "predicted_classes = json.loads(predictions)\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-senior",
   "metadata": {},
   "source": [
    "The code above uses the Azure ML SDK to connect to the containerized web service and use it to generate predictions from your iris classification model. In production, a model is likely to be consumed by business applications that do not use the Azure ML SDK, but simply make HTTP requests to the web service.\n",
    "\n",
    "Let's determine the URL to which these applications must submit their requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "postal-drink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://73e4ec73-6002-4464-8c50-a0a893f17628.southeastasia.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "\n",
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-repository",
   "metadata": {},
   "source": [
    "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "marked-audit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [6.7, 3.0, 5.2, 2.3] Iris-verginica\n",
      "Patient [5.1, 3.5, 1.4, 0.2] Iris-sectosa\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[6.7,3.0,5.2,2.3],\n",
    "        [5.1,3.5,1.4,0.2]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-mandate",
   "metadata": {},
   "source": [
    "You've deployed your web service as an Azure Container Instance (ACI) service that requires no authentication. This is fine for development and testing, but for production you should consider deploying to an Azure Kubernetes Service (AKS) cluster and enabling authentication. This would require REST requests to include an Authorization header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-credit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
